{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchnorm (O)\n",
    "# random mask=> random sampling\n",
    "# std 有點大 around 10 > normalize to 1 (0)\n",
    "# mean around [-1,1], maybe we can abs() => mean to 0 (O)\n",
    "# # of FC layers <5, 遞減 256 64 16 4 (O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the data into 0 mean and 1 var\n",
    "from sklearn import preprocessing\n",
    "for i in range(X_train_valid.shape[0]):\n",
    "        X_train_valid[i] = preprocessing.scale(X_train_valid[i])\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test[i] = preprocessing.scale(X_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Not use the last 3 of the 25 electrodes, which are EOG (rather than EEG) electrodes\n",
    "X_train_valid = X_train_valid[:,:-3,:]\n",
    "X_test = X_test[:,:-3,:]\n",
    "\n",
    "# Change the timestep to the second column\n",
    "X_train_valid = np.transpose(X_train_valid, (0, 2, 1))\n",
    "X_test = np.transpose(X_test, (0, 2, 1))\n",
    "\n",
    "# Modify the y to categorical form\n",
    "from keras.utils import np_utils\n",
    "num_classes = np.unique(y_train_valid).size\n",
    "y_train_valid = y_train_valid - min(y_train_valid)\n",
    "y_test = y_test - min(y_test)\n",
    "y_train_valid = np_utils.to_categorical(y_train_valid, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 1000, 22)\n",
      "Test data shape: (443, 1000, 22)\n",
      "Training/Valid target shape: (2115, 4)\n",
      "Test target shape: (443, 4)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "dropout_prob = 0.5\n",
    "\n",
    "# Parameters for LSTM network\n",
    "lstm_outputs = 256\n",
    "_, timesteps, data_dim = X_train_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7, decay=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 1000, 256)         285696    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1000, 256)         1024      \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 830,932\n",
      "Trainable params: 829,748\n",
      "Non-trainable params: 1,184\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(lstm_outputs, activation= 'tanh', recurrent_activation='hard_sigmoid', \n",
    "               dropout=0.5,  recurrent_dropout = 0.5, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension lstm_outputs\n",
    "model.add(BatchNormalization())\n",
    "# model.add(LSTM(lstm_outputs, return_sequences=True))  # returns a sequence of vectors of dimension lstm_outputs\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(lstm_outputs, activation= 'tanh', recurrent_activation='hard_sigmoid', \n",
    "               dropout=0.5,  recurrent_dropout = 0.5))  # return a single vector of dimension lstm_outputs\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(dropout_prob))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(dropout_prob))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "SAVED_MODEL_ARCHITECTURE_PATH = '/Users/WenHsu/Documents/ECE 239 NN/Project/project/saved_models/Keras_RNN_Architecture.json'\n",
    "with open(SAVED_MODEL_ARCHITECTURE_PATH, 'w') as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_MODEL_WEIGHTS_PATH = '/Users/WenHsu/Documents/ECE 239 NN/Project/project/saved_models/Keras_RNN.h5'\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath= SAVED_MODEL_WEIGHTS_PATH, \n",
    "                               verbose=1, save_best_only=True)\n",
    "history = model.fit(X_train_valid, y_train_valid, batch_size=batch_size, \n",
    "                    epochs=epochs, verbose=1, callbacks=[checkpointer], validation_split = 0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "from keras.models import model_from_json\n",
    "with open(SAVED_MODEL_ARCHITECTURE_PATH, 'r') as f:\n",
    "    model = model_from_json(f.read())\n",
    "\n",
    "model.load_weights(SAVED_MODEL_WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### get predicted action for each signal in test set\n",
    "predictions = model.predict(X_test)\n",
    "# print out test accuracy\n",
    "test_accuracy = 100*np.sum(np.argmax(predictions,axis =1)==np.argmax(y_test, axis=1))/len(predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
